{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 1 - Predicting Life Insurance Policy Lapse\n",
    "\n",
    "Project Idea: Build a model to predict whether a life insurance policy will lapse within a given period based on customer demographics and policy characteristics.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Collect data on life insurance policies, including customer demographics, policy details, and lapse status.\n",
    "    Preprocess the data, handle missing values, and create features.\n",
    "    Train a classification model to predict policy lapse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\__init__.py:87\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     84\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     85\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     )\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[0;32m     90\u001b[0m     __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_versions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    134\u001b[0m     ]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\utils\\__init__.py:28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m all_estimators\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version, threadpool_info\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmurmurhash\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m murmurhash3_32\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     _is_arraylike_not_scalar,\n\u001b[0;32m     31\u001b[0m     _is_pandas_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     indexable,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Do not deprecate parallel_backend and register_parallel_backend as they are\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# needed to tune `scikit-learn` behavior and have different effect if called\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# from the vendored version or or the site-package version. The other are\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# utilities that are independent of scikit-learn so they are not part of\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# scikit-learn public API.\u001b[39;00m\n",
      "File \u001b[1;32msklearn\\\\utils\\\\murmurhash.pyx:1\u001b[0m, in \u001b[0;36minit sklearn.utils.murmurhash\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'age': [25, 35, 45, 55, 65],\n",
    "    'income': [30000, 50000, 70000, 90000, 110000],\n",
    "    'policy_term': [10, 15, 20, 25, 30],\n",
    "    'premium': [200, 300, 400, 500, 600],\n",
    "    'policy_lapse': [0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "X = df[['age', 'income', 'policy_term', 'premium']]\n",
    "y = df['policy_lapse']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 2 - Estimating Life Insurance Premiums\n",
    "\n",
    "Project Idea: Develop a regression model to estimate the premium of a life insurance policy based on customer demographics and policy details.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Collect data on life insurance policies, including customer demographics and premium amounts.\n",
    "    Preprocess the data, handle missing values, and create features.\n",
    "    Train a regression model to predict premiums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'age': [25, 35, 45, 55, 65],\n",
    "    'income': [30000, 50000, 70000, 90000, 110000],\n",
    "    'policy_term': [10, 15, 20, 25, 30],\n",
    "    'premium': [200, 300, 400, 500, 600]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "X = df[['age', 'income', 'policy_term']]\n",
    "y = df['premium']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3 - Predicting Life Expectancy for Underwriting\n",
    "\n",
    "Project Idea: Create a model to predict life expectancy of applicants for underwriting purposes using demographic and health data.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Collect data on applicants, including demographic and health information.\n",
    "    Preprocess the data, handle missing values, and create features.\n",
    "    Train a regression model to predict life expectancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'age': [30, 40, 50, 60, 70],\n",
    "    'bmi': [22, 28, 26, 30, 24],\n",
    "    'smoker': [0, 1, 1, 0, 0],\n",
    "    'exercise_frequency': [3, 1, 2, 4, 3],\n",
    "    'life_expectancy': [80, 75, 70, 85, 82]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "X = df[['age', 'bmi', 'smoker', 'exercise_frequency']]\n",
    "y = df['life_expectancy']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R^2 Score: {r2_score(y_test, y_pred)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 -  Customer Retention Prediction\n",
    "\n",
    "Project Idea: Build a model to predict the likelihood of customers renewing their life insurance policies.\n",
    "\n",
    "Steps:\n",
    "\n",
    "    Collect data on customers and their policy renewal history.\n",
    "    Preprocess the data, handle missing values, and create features.\n",
    "    Train a classification model to predict customer retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'age': [25, 35, 45, 55, 65],\n",
    "    'income': [30000, 50000, 70000, 90000, 110000],\n",
    "    'policy_term': [10, 15, 20, 25, 30],\n",
    "    'premium': [200, 300, 400, 500, 600],\n",
    "    'renewed': [1, 0, 1, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess data\n",
    "X = df[['age', 'income', 'policy_term', 'premium']]\n",
    "y = df['renewed']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
